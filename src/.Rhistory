rm(list = setdiff(ls(), "data"))
rm(list = setdiff(ls(), "data"))
source("utils.r")
source("PrepareData.r")
source("ActiveLearningTest.r")
library('ggplot2')
raw_data = read.csv("../Datasets/JobChanges/aug_train.csv", header=T, sep=",", na.strings=c("","NA"))
#raw_data <- raw_data[1:3000,]
data <- prepareData(raw_data)
k <- 1
initial_train_size <- 2
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
wykres = ggplot() +
geom_line(data = accuracies_random, aes(x = LabelledDataSize, y = Accuracy), color = "blue") +
geom_line(data = accuracies_conf, aes(x = LabelledDataSize,, y = Accuracy), color = "red") +
xlab('Labelled Data Size') +
ylab('Accuracy')
print(wykres)
initial_train_size <- 2
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
wykres = ggplot() +
geom_line(data = accuracies_random, aes(x = LabelledDataSize, y = Accuracy), color = "blue") +
geom_line(data = accuracies_conf, aes(x = LabelledDataSize,, y = Accuracy), color = "red") +
xlab('Labelled Data Size') +
ylab('Accuracy')
print(wykres)
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
View(data)
View(data)
View(raw_data)
View(raw_data)
View(data)
View(data)
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
accuracies <- c()
## --------------------------------------------------------------------------------
## ---------------- Podzielenie zbioru na pule i zbior testowy --------------------
## --------------------------------------------------------------------------------
test_idx <- 0.8 * nrow(data) # ostatnie 20% danych to zbior testowy
data_pool <- data[1:test_idx,]
data_test <- data[-test_idx,]
## --------------------------------------------------------------------------------
## --Wybranie k próbek z puli do początkowego zbioru trenującego i podpisanie ich--
## --------------------------------------------------------------------------------
set.seed(1234)
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
# loops <- nrow(validating_set)/k
sample_count <- c()
for (i in 1:iterations) {
## ------------------------------------------------------------------------
## -----------Trenowanie modelu za pomocą zbioru trenującego---------------
## ------------------------------------------------------------------------
model <- svm(target ~ ., data = training_set, probability = TRUE)
print(model)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation <- predict(model, validating_set, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test <- predict(model, data_test)
results <- data.frame(pred_test, data_test$target)
colnames(results) <- c('Predicted', 'Actual')
accuracy <- GetAccuracy(results)
accuracies <- append(accuracies, accuracy)
sample_count <- append(sample_count, initial_train_size + k*i)
print(paste("Accuracy:", gsub(" ", "", paste(accuracy * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs <- attr(pred_validation, "probabilities")
scores <- abs(probabs[,1] - probabs[,2])
scores_df <- data.frame(1:nrow(validating_set), probabs, scores)
colnames(scores_df) <- c('Index', 'Probability', 'Score')
colnames(scores_df) <- c('Index', 'Probability', 'Score')
scores_df <- data.frame(1:nrow(validating_set), probabs, scores)
colnames(scores_df) <- c('Index', 'Probability', 'Score')
if (random) {
scores_df <- scores_df[sample(nrow(scores)),] # shuffle data
} else {
scores_df <- scores_df[order(scores),]
}
scores_df_k <- scores_df[1:k,]
chosen_samples <- validating_set[scores_df_k$Index,]
print(paste("training data size", nrow(training_set)))
training_set <- rbind(training_set, chosen_samples)
validating_set <- validating_set[-scores_df_k$Index,]
print(i)
for (i in 1:iterations) {
## ------------------------------------------------------------------------
## -----------Trenowanie modelu za pomocą zbioru trenującego---------------
## ------------------------------------------------------------------------
model <- svm(target ~ ., data = training_set, probability = TRUE)
print(model)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation <- predict(model, validating_set, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test <- predict(model, data_test)
results <- data.frame(pred_test, data_test$target)
colnames(results) <- c('Predicted', 'Actual')
accuracy <- GetAccuracy(results)
accuracies <- append(accuracies, accuracy)
sample_count <- append(sample_count, initial_train_size + k*i)
print(paste("Accuracy:", gsub(" ", "", paste(accuracy * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs <- attr(pred_validation, "probabilities")
scores <- abs(probabs[,1] - probabs[,2])
scores_df <- data.frame(1:nrow(validating_set), probabs, scores)
colnames(scores_df) <- c('Index', 'Probability', 'Score')
if (random) {
scores_df <- scores_df[sample(nrow(scores)),] # shuffle data
} else {
scores_df <- scores_df[order(scores),]
}
scores_df_k <- scores_df[1:k,]
chosen_samples <- validating_set[scores_df_k$Index,]
print(paste("training data size", nrow(training_set)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set <- rbind(training_set, chosen_samples)
validating_set <- validating_set[-scores_df_k$Index,]
print(i)
}
acc_data_frame <- data.frame(sample_count, accuracies)
#colnames(acc_data_frame) <- c('LabelledDataSize', 'Accuracy')
return (acc_data_frame)
ActiveLearningTest <- function(data, initial_train_size, k, iterations, random = FALSE) {
accuracies <- c()
## --------------------------------------------------------------------------------
## ---------------- Podzielenie zbioru na pule i zbior testowy --------------------
## --------------------------------------------------------------------------------
test_idx <- 0.8 * nrow(data) # ostatnie 20% danych to zbior testowy
data_pool <- data[1:test_idx,]
data_test <- data[-test_idx,]
## --------------------------------------------------------------------------------
## --Wybranie k próbek z puli do początkowego zbioru trenującego i podpisanie ich--
## --------------------------------------------------------------------------------
set.seed(1234)
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
# loops <- nrow(validating_set)/k
sample_count <- c()
for (i in 1:iterations) {
## ------------------------------------------------------------------------
## -----------Trenowanie modelu za pomocą zbioru trenującego---------------
## ------------------------------------------------------------------------
model <- svm(target ~ ., data = training_set, probability = TRUE)
print(model)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation <- predict(model, validating_set, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test <- predict(model, data_test)
results <- data.frame(pred_test, data_test$target)
colnames(results) <- c('Predicted', 'Actual')
accuracy <- GetAccuracy(results)
accuracies <- append(accuracies, accuracy)
sample_count <- append(sample_count, initial_train_size + k*i)
print(paste("Accuracy:", gsub(" ", "", paste(accuracy * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs <- attr(pred_validation, "probabilities")
scores <- abs(probabs[,1] - probabs[,2])
scores_df <- data.frame(1:nrow(validating_set), probabs, scores)
colnames(scores_df) <- c('Index', 'Probability', 'Score')
if (random) {
scores_df <- scores_df[sample(nrow(scores)),] # shuffle data
} else {
scores_df <- scores_df[order(scores),]
}
scores_df_k <- scores_df[1:k,]
chosen_samples <- validating_set[scores_df_k$Index,]
print(paste("training data size", nrow(training_set)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set <- rbind(training_set, chosen_samples)
validating_set <- validating_set[-scores_df_k$Index,]
print(i)
}
acc_data_frame <- data.frame(sample_count, accuracies)
#colnames(acc_data_frame) <- c('LabelledDataSize', 'Accuracy')
return (acc_data_frame)
}
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
raw_data = read.csv("../Datasets/JobChanges/aug_train.csv", header=T, sep=",", na.strings=c("","NA"))
#raw_data <- raw_data[1:3000,]
data <- prepareData(raw_data)
k <- 1
initial_train_size <- 2
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
wykres = ggplot() +
geom_line(data = accuracies_random, aes(x = LabelledDataSize, y = Accuracy), color = "blue") +
geom_line(data = accuracies_conf, aes(x = LabelledDataSize,, y = Accuracy), color = "red") +
xlab('Labelled Data Size') +
ylab('Accuracy')
print(wykres)
k <- 1
initial_train_size <- 2
# Demonstration of the active learning testing function
accuracies_random <- ActiveLearningTest(data, initial_train_size, k, 100, TRUE)
accuracies_conf <- ActiveLearningTest(data, initial_train_size, k, 100)
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')
source('~/Active-learning-svm-zum/src/Main-arek.r')

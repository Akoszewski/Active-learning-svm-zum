print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(1:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(validating_set_conf), probabs_conf, scores_conf)
colnames(scores_random_df) <- c('Index', 'Probability', 'Score')
colnames(scores_conf_df) <- c('Index', 'Probability', 'Score')
scores_random_df <-scores_random_df[sample(nrow(scores_random_df)),] # shuffle data
scores_conf_df <-scores_conf_df[order(scores_conf_df$Score),] # sort data
scores_random_df_k <- scores_random_df[1:k,]
scores_conf_df_k <- scores_conf_df[1:k,]
chosen_samples_random <- validating_set[scores_random_df_k$Index,]
chosen_samples_conf <- validating_set[scores_conf_df_k$Index,]
print(paste("training_random data size:", nrow(training_set_random)))
print(paste("training_conf data size:", nrow(training_set_conf)))
# --------------------------------------------------------------------------------
## -----Przeniesienie wybranych próbek ze zbioru walidacyjnego do treningowego----
## -------------------------------------------------------------------------------
training_set_random <- rbind(training_set_random, chosen_samples_random)
training_set_conf <- rbind(training_set_conf, chosen_samples_conf)
validating_set_random <- validating_set[-scores_random_df_k$Index+2,]
validating_set_conf <- validating_set[-scores_conf_df_k$Index+2,]
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
training_set_random <- training_set;
training_set_conf <- training_set;
validating_set_random <- validating_set;
validating_set_conf <- validating_set;
accuracies_random <- c()
accuracies_conf <- c()
sample_count <- c()
## ------------------------------------------------------------------------
## -----------Trenowanie modelu za pomocą zbioru trenującego---------------
## ------------------------------------------------------------------------
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(0:nrow(validating_set_random), probabs_random, scores_random)
scores_conf_df <- data.frame(0:nrow(validating_set_conf), probabs_conf, scores_conf)
View(scores_conf_df)
View(scores_conf_df)
View(scores_conf_df)
scores_random_df <- data.frame(2:nrow(validating_set_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(2:nrow(validating_set_conf)+1, probabs_conf, scores_conf)
scores_random_df <- data.frame(20:nrow(validating_set_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(20:nrow(validating_set_conf)+1, probabs_conf, scores_conf)
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
training_set_random <- training_set;
training_set_conf <- training_set;
validating_set_random <- validating_set;
validating_set_conf <- validating_set;
accuracies_random <- c()
accuracies_conf <- c()
sample_count <- c()
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
training_set_random <- training_set;
training_set_conf <- training_set;
validating_set_random <- validating_set;
validating_set_conf <- validating_set;
accuracies_random <- c()
accuracies_conf <- c()
sample_count <- c()
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(20:nrow(validating_set_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(20:nrow(validating_set_conf)+1, probabs_conf, scores_conf)
training_set <- data_pool[1:initial_train_size, ]; # str(training_set)
validating_set <- data_pool[-initial_train_size, ]; # str(validating_set)
training_set_random <- training_set;
training_set_conf <- training_set;
validating_set_random <- validating_set;
validating_set_conf <- validating_set;
accuracies_random <- c()
accuracies_conf <- c()
sample_count <- c()
## ------------------------------------------------------------------------
## -----------Trenowanie modelu za pomocą zbioru trenującego---------------
## ------------------------------------------------------------------------
model_random <- svm(target ~ ., data = training_set_random, kernel = "linear", probability = TRUE)
model_conf <- svm(target ~ ., data = training_set_conf, kernel = "linear", probability = TRUE)
print(model_random)
print(model_conf)
## --------------------------------------------------------------------------------
## ----------------------Predykcja na zbiorze walidacyjnym-------------------------
## --------------------------------------------------------------------------------
pred_validation_random <- predict(model_random, validating_set_random, probability = TRUE)
pred_validation_conf <- predict(model_conf, validating_set_conf, probability = TRUE)
## --------------------------------------------------------------------------------
## -----------Użycie modelu na zbiorze testowym i zmierzenie wydajności------------
## --------------------------------------------------------------------------------
pred_test_random <- predict(model_random, data_test)
pred_test_conf <- predict(model_conf, data_test)
results_random <- data.frame(pred_test_random, data_test$target)
results_conf <- data.frame(pred_test_conf, data_test$target)
colnames(results_random) <- c('Predicted', 'Actual')
colnames(results_conf) <- c('Predicted', 'Actual')
accuracy_random <- GetAccuracy(results_random)
accuracy_conf <- GetAccuracy(results_conf)
accuracies_random <- append(accuracies_random, accuracy_random)
accuracies_conf <- append(accuracies_conf, accuracy_conf)
sample_count <- append(sample_count, initial_train_size + k * i)
print(paste("Accuracy Random:", gsub(" ", "", paste(accuracy_random * 100, "%"))))
print(paste("Accuracy Confidence:", gsub(" ", "", paste(accuracy_conf * 100, "%"))))
## --------------------------------------------------------------------------------
## -----------Wybranie k próbek niosących najwięcej informacji---------------------
## --------------------------------------------------------------------------------
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(20:nrow(validating_set_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(20:nrow(validating_set_conf)+1, probabs_conf, scores_conf)
probabs_random <- attr(pred_validation_random, "probabilities");
probabs_conf <- attr(pred_validation_conf, "probabilities");
scores_random <- abs(probabs_random[,1] - probabs_random[,2])
scores_conf <- abs(probabs_conf[,1] - probabs_conf[,2])
scores_random_df <- data.frame(nrow(pred_validation_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(nrow(pred_validation_conf)+1, probabs_conf, scores_conf)
scores_random_df <- data.frame(1:nrow(pred_validation_random)+1, probabs_random, scores_random)
scores_conf_df <- data.frame(1:nrow(pred_validation_conf)+1, probabs_conf, scores_conf)
rm(list = setdiff(ls(), "data"))
source("utils.r")
source("PrepareData.r")
rm(list = setdiff(ls(), "data"))
source("utils.r")
rm(list = setdiff(ls(), "data"))
rm(list = setdiff(ls(), "data"))
View(chosen_samples_conf)
rm(list = setdiff(ls(), "data"))
rm(list = setdiff(ls(), "data"))
raw_data = read.csv("../Datasets/JobChanges/aug_train.csv", header=T, sep=",", na.strings=c("","NA"))
raw_data <- raw_data[1:1000,]
data <- prepareData(raw_data)
rm(list = setdiff(ls(), "data"))
source("utils.r")
source("PrepareData.r")
k <- 1
raw_data = read.csv("../Datasets/JobChanges/aug_train.csv", header=T, sep=",", na.strings=c("","NA"))
data <- prepareData(raw_data)
